---
title: "Statistical Rethinking 2nd edition Homework 8 in INLA"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE)
```

```{r libraries, message= FALSE}

library(tidyverse)
library(rethinking)
library(dagitty)
library(INLA)
library(knitr)
library(stringr)
```


# 1. 

**Revisit the Reed frog survival data, data(reedfrogs),and add the predation and size treatment variables to the varying intercepts model. Consider models with either predictor alone, both predictors, as well as a model including their interaction. What do you infer about the causal influence of these predictor variables? Also focus on the inferred variation across tanks (the σ across tanks). Explain why it changes as it does across models with different predictors included.**

```{r 8.1 dt}
library(rethinking) 
data(reedfrogs)
d <- reedfrogs
```

## 1.1 varying intercepts model

Si ∼ Binomial(Ni, pi)

logit(pi) = αtank[i]       

αj ∼ Normal($\bar{\alpha}$, σ)                             [adaptive prior]    

$\bar{\alpha}$ ∼ Normal(0, 1.5)                            [prior for average tank]

σ ∼ Exponential(1)                              [prior for standard deviation of tanks]


### 1.1 rethinking

```{r 8.1 dt re}
dat <- list(
S = d$surv,
n = d$density,
tank = 1:nrow(d),
pred = ifelse( d$pred=="no" , 0L , 1L ), 
size_ = ifelse( d$size=="small" , 1L , 2L )
)
```


```{r 8.1.1 re}
m1.1 <- ulam( alist(
S ~ binomial( n , p ),
logit(p) <- a[tank],
a[tank] ~ normal( a_bar , sigma ), 
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )
), data=dat , chains=4 , cores=4 , log_lik=TRUE )
precis(m1.1, depth= 2)
```

### 1.1 INLA 

following example: https://people.bath.ac.uk/jjf23/brinla/reeds.html

**Here I'm missing custom priors**
I'll use a half cauchy prior for the $\sigma$ to constrain it to >0 numbers, which is what the exponential does as well. 

```{r 8.1.1 inla}

library(brinla)
library(INLA)

d1.i <- d %>% 
  mutate(tank = row_number(), 
         pred.no= na_if(if_else(pred=="no", 1, 0), 0),
         pred.yes= na_if(if_else(pred=="pred", 1, 0), 0),
         size.small= na_if(if_else(size=="small", 1, 0), 0),
         size.big= na_if(if_else(size=="big", 1, 0), 0)
         ) 

# number of trials is d1.i$density

halfcauchy = "expression:
              lambda = 0.022;
              precision = exp(log_precision);
              logdens = -1.5*log_precision-log(pi*lambda)-log(1+1/(precision*lambda^2));
              log_jacobian = log_precision;
              return(logdens+log_jacobian);"

hcprior = list(prec = list(prior = halfcauchy))
  
m1.1.i <- inla(surv ~ 1 + f(tank, model="iid", hyper = hcprior), data= d1.i, family = "binomial", 
              Ntrials = density, 
              control.family = list(control.link=list(model="logit")),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, dic=TRUE, waic= TRUE))
summary(m1.1.i)

m1.1.i$summary.fixed

m1.1.i$summary.hyperpar

bri.hyperpar.summary(m1.1.i)


```
it looks like the intercept mean and sd correspond to the $\bar{\alpha}$ mean and sd, and the SD for tank corresponds to the $\sigma$. this makes sense, because the $\bar{\alpha}$ is the average baseline survival for all the tadpoles, which is what the intercept is. 
**BUT I WOULD LOVE IF SOMEONE ELSE CONFIRMED THIS INTERPRETATION**. 

## 1.2 varying intercepts + predation

Si ∼ Binomial(Ni, pi)

logit(pi) = αtank[i]  + $\beta$[pred] 

$\beta$∼ Normal(-0.5,1)

αj ∼ Normal($\bar{\alpha}$, σ)                             [adaptive prior]     

$\bar{\alpha}$ ∼ Normal(0, 1.5)                            [prior for average tank]

σ ∼ Exponential(1)                              [prior for standard deviation of tanks]


### 1.2 rethinking

```{r 8.1.2 re}
# pred
m1.2 <- ulam(
alist(
S ~ binomial( n , p ),
logit(p) <- a[tank] + bp*pred, 
a[tank] ~ normal( a_bar , sigma ), 
bp ~ normal( -0.5 , 1 ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )
), data=dat , chains=4 , cores=4 , log_lik=TRUE ) 

precis(m1.2)
```


### 1.2 inla
```{r 8.1.2 inla}

library(brinla)
library(INLA)

# number of trials is d1.i$density

halfcauchy = "expression:
              lambda = 0.022;
              precision = exp(log_precision);
              logdens = -1.5*log_precision-log(pi*lambda)-log(1+1/(precision*lambda^2));
              log_jacobian = log_precision;
              return(logdens+log_jacobian);"

hcprior = list(prec = list(prior = halfcauchy))
  
m1.2.i <- inla(surv ~ 1 + pred + f(tank, model="iid", hyper = hcprior), data= d1.i, family = "binomial", 
              Ntrials = density, 
              control.fixed = list(
        mean= -0.5,
        prec= 1, 
        mean.intercept= 0, 
        prec.intercept= 1.5),
              control.family = list(control.link=list(model="logit")),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, dic=TRUE, waic= TRUE))
summary(m1.2.i)

m1.2.i$summary.fixed

bri.hyperpar.summary(m1.2.i)


```


## 1.3 varying intercepts + size

Si ∼ Binomial(Ni, pi)

logit(pi) = αtank[i]  + $\beta$size    

$\beta$∼ Normal(0 , 0.5 )
αj ∼ Normal($\bar{\alpha}$, σ)                             [adaptive prior]   

$\bar{\alpha}$ ∼ Normal(0, 1.5)                            [prior for average tank]

σ ∼ Exponential(1)                              [prior for standard deviation of tanks]


### 1.3 rethinking

```{r 8.1.3 re}
library(rethinking) 
data(reedfrogs)
d <- reedfrogs

# size
m1.3 <- ulam( alist(
S ~ binomial( n , p ),
logit(p) <- a[tank] + s[size_], 
a[tank] ~ normal( a_bar , sigma ), 
s[size_] ~ normal( 0 , 0.5 ), 
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )
), data=dat , chains=4 , cores=4 , log_lik=TRUE )


precis(m1.3,  depth=2)
```


### 1.3 inla
```{r 8.1.3 inla}

library(brinla)
library(INLA)

d1.i <- d %>% 
  mutate(tank = row_number(), 
         pred.no= na_if(if_else(pred=="no", 1, 0), 0),
         pred.yes= na_if(if_else(pred=="pred", 1, 0), 0),
         size.small= na_if(if_else(size=="small", 1, 0), 0),
         size.big= na_if(if_else(size=="big", 1, 0), 0)
         ) 

# number of trials is d1.i$density

halfcauchy = "expression:
              lambda = 0.022;
              precision = exp(log_precision);
              logdens = -1.5*log_precision-log(pi*lambda)-log(1+1/(precision*lambda^2));
              log_jacobian = log_precision;
              return(logdens+log_jacobian);"

hcprior = list(prec = list(prior = halfcauchy))
  
m1.3.i <- inla(surv ~ 1 + size.small+ size.big + f(tank, model="iid", hyper = hcprior), data= d1.i, family = "binomial", 
              Ntrials = density, 
              control.fixed = list(
        mean= 0,
        prec= 0.5, 
        mean.intercept= 0, 
        prec.intercept= 1.5),
              control.family = list(control.link=list(model="logit")),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, dic=TRUE, waic= TRUE))
summary(m1.3.i)

m1.3.i$summary.fixed

bri.hyperpar.summary(m1.3.i)


```

** these estimates are super off, probably something is wrong**

## 1.4 varying intercepts + predation + size

Si ∼ Binomial(Ni, pi)

logit(pi) = αtank[i]  + $\beta$size + $\gamma$size  

$\gamma$ ∼ Normal(0 , 0.5)

$\beta$ ∼ Normal(-0.5,1)
αj ∼ Normal($\bar{\alpha}$, σ)                             [adaptive prior]    

$\bar{\alpha}$ ∼ Normal(0, 1.5)                            [prior for average tank]

σ ∼ Exponential(1)                              [prior for standard deviation of tanks]

### 1.4 rethinking

```{r 8.1.4 re}
# pred + size 
m1.4 <- ulam(
alist(
S ~ binomial( n , p ),
logit(p) <- a[tank] + bp*pred + s[size_], 
a[tank] ~ normal( a_bar , sigma ),
bp ~ normal( -0.5 , 1 ),
s[size_] ~ normal( 0 , 0.5 ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )
), data=dat , chains=4 , cores=4 , log_lik=TRUE )



precis(m1.4, depth=2)
```


### 1.4 inla
```{r 8.1.4 inla}

library(brinla)
library(INLA)

# number of trials is d1.i$density

halfcauchy = "expression:
              lambda = 0.022;
              precision = exp(log_precision);
              logdens = -1.5*log_precision-log(pi*lambda)-log(1+1/(precision*lambda^2));
              log_jacobian = log_precision;
              return(logdens+log_jacobian);"

hcprior = list(prec = list(prior = halfcauchy))
  
m1.4.i <- inla(surv ~ 1 + pred + size.small+ size.big + f(tank, model="iid", hyper = hcprior), data= d1.i, family = "binomial", 
              Ntrials = density, 
              control.fixed = list(
        mean= list(pred= -0.5,size.small= 0, size.big= 0 ),
        prec= list(pred= 1,size.small= 1, size.big= 1 ), 
        mean.intercept= 0, 
        prec.intercept= 1.5),
              control.family = list(control.link=list(model="logit")),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, dic=TRUE, waic= TRUE))
summary(m1.4.i)

m1.4.i$summary.fixed

bri.hyperpar.summary(m1.4.i)


```

## 1.5 varying intercepts + predation + size + predation*size

Si ∼ Binomial(Ni, pi)


**this formula's wrong**

logit(pi) = αtank[i]  + $\beta$predation + $\gamma$size + $\eta$size*predation

$\gamma$ ∼ Normal(0 , 0.5)
$\beta$ ∼ Normal(-0.5,1)
αj ∼ Normal($\bar{\alpha}$, σ)                             [adaptive prior]    
$\bar{\alpha}$ ∼ Normal(0, 1.5)                            [prior for average tank]
σ ∼ Exponential(1)                              [prior for standard deviation of tanks]

### 1.5 rethinking

```{r 8.1.5 re}

# pred + size + interaction 
m1.5 <- ulam(
alist(
S ~ binomial( n , p),
logit(p) <- a_bar + z[tank]*sigma + s[size_]+ bp[size_]*pred , 
z[tank] ~ normal( 0, 1), 
bp[size_] ~ normal(-0.5,1), 
s[size_] ~ normal( 0 , 0.5 ), 
a_bar ~ normal( 0 , 1.5 ), 
sigma ~ exponential( 1 )
), data=dat , chains=4 , cores=4 , log_lik=TRUE )



precis(m1.5, depth=2)
```


I coded the interaction model using a non-centered parameterization. The interaction itself is done by creating a bp parameter for each size value. In this way, the effect of pred depends upon size.

### 1.5 inla
```{r 8.1.5 inla}

library(brinla)
library(INLA)


# number of trials is d1.i$density

halfcauchy = "expression:
              lambda = 0.022;
              precision = exp(log_precision);
              logdens = -1.5*log_precision-log(pi*lambda)-log(1+1/(precision*lambda^2));
              log_jacobian = log_precision;
              return(logdens+log_jacobian);"

hcprior = list(prec = list(prior = halfcauchy))
  
m1.5.i <- inla(surv ~ 1 + size.small+ size.big + pred*size.small + pred*size.big + f(tank, model="iid", hyper = hcprior), data= d1.i, family = "binomial", 
              Ntrials = density, 
              control.fixed = list(
        mean= list(pred= -0.5,size.small= 0, size.big= 0 ),
        prec= list(pred= 1,size.small= 1, size.big= 1 ), 
        mean.intercept= 0, 
        prec.intercept= 1.5),
              control.family = list(control.link=list(model="logit")),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, dic=TRUE, waic= TRUE))
summary(m1.5.i )

m1.5.i$summary.fixed

bri.hyperpar.summary(m1.5.i)


```

## compare using WAIC

#### compare rethinking 

```{r 8 compare re}
rethinking::compare( m1.1 , m1.2 , m1.3 , m1.4 , m1.5 )
```

These models are really very similar in expected out-of-sample accuracy. The tank variation is huge. But take a look at the posterior distributions for predation and size. You’ll see that predation does seem to matter, as you’d expect. Size matters a lot less. So while predation doesn’t explain much of the total variation, there is plenty of evidence that it is a real effect. Remember: We don’t select a model using WAIC (or LOO). A predictor can make little difference in total accuracy but still be a real causal effect.

#### compare inla

```{r compare inla}

inla.models.8.1 <- list(m1.1.i, m1.2.i,m1.3.i, m1.4.i, m1.5.i )

extract.waic <- function (x){
  x[["waic"]][["waic"]]
}

waic.8.1 <- bind_cols(model = c("m1.1.i","m1.2.i","m1.3.i", "m1.4.i", "m1.5.i" ), waic = sapply(inla.models.8.1 ,extract.waic))

waic.8.1
```


Let’s look at all the sigma posterior distributions:
The two models that omit predation, m1.1 and m1.3, have larger values of sigma. This is because predation explains some of the variation among tanks. So when you add it to the model, the variation in the tank intercepts gets smaller.


```{r sigma.8.1 plot }

sigma.8.1 <- bind_cols( model= c("m1.1.i","m1.2.i","m1.3.i", "m1.4.i", "m1.5.i" ), do.call(rbind.data.frame, lapply(inla.models.8.1 ,bri.hyperpar.summary)))


sigma.8.1

sigma.8.1.plot <-  ggplot(data= sigma.8.1, aes(y=model, x=mean, label=model)) +
    geom_point(size=4, shape=19) +
    geom_errorbarh(aes(xmin=q0.025, xmax=q0.975), height=.3) +
    coord_fixed(ratio=.3) +
    theme_bw()

sigma.8.1.plot


```



# 2. 

**In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 2000, a typical Bengali woman had only 2 or 3. You’re going to look at a historical set of data, when contraception was widely available but many families chose not to use it. These data reside in data(bangladesh) and come from the 1988 Bangladesh Fertility Survey. Each row is one of 1934 women. There are six variables, but you can focus on two of them for this practice problem:**

**(1) district: ID number of administrative district each woman resided in**

**(2) use.contraception: An indicator (0/1) of whether the woman was using contraception**

**Focus on predicting use.contraception, clustered by district_id. Fit both:** 

**1) a traditional fixed-effects model that uses an index variable for district**

**2) a multilevel model with varying intercepts for district.** 

Plot the predicted proportions of women in each district using contraception, for both the fixed-effects model and the varying-effects model. That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical. Make one plot for each model, or layer them on the same plot, as you prefer. How do the models disagree? Can you explain the pattern of disagreement? In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences?**


```{r 8.2 data}
library(rethinking)
data(bangladesh)
d <- bangladesh
```

The first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. Recall that these values will be index values inside the model. If there are gaps, you’ll have parameters for which there is no data to inform them. Worse, the model probably won’t run. Look at the unique values of the district variable:

```{r 8.2}
sort(unique(d$district))
```

District 54 is absent. So district isn’t yet a good index variable, because it’s not contiguous. This is easy to fix. Just make a new variable that is contiguous. This is enough to do it:

```{r 8.2 cint}
d$district_id <- as.integer(as.factor(d$district)) 
sort(unique(d$district_id))
```

Now there are 60 values, contiguous integers 1 to 60.

## 2.1 traditional fixed-effects model that uses an index variable for district


### 2.1 rethinking

```{r 8.2.1 re}

dat_list <- list(
C = d$use.contraception, 
did = d$district_id
)

m2.1 <- ulam( alist(
C ~ bernoulli( p ),
logit(p) <- a[did],
a[did] ~ normal( 0 , 1.5 )
) , data=dat_list , chains=4 , cores=4 , log_lik=TRUE )

precis(m2.1, depth = 2)

```

### 2.1 inla

```{r 8.2.1 inla}

library(brinla)
library(INLA)
library(tidyverse)

d2.i <- d %>% 
  mutate(did= paste("d", as.integer(d$district_id), sep= "."), 
         d.value= 1
         ) %>% 
  spread(did, d.value)

#use this to quickly make a list of the index vbles to include in the model 
did_formula <- paste("d", 1:60, sep=".", collapse = "+")


m2.1.i <- inla(use.contraception ~ d.1+d.2+d.3+d.4+d.5+d.6+d.7+d.8+d.9+d.10+d.11+d.12+d.13+d.14+d.15+d.16+d.17+d.18+d.19+d.20+d.21+d.22+d.23+d.24+d.25+d.26+d.27+d.28+d.29+d.30+d.31+d.32+d.33+d.34+d.35+d.36+d.37+d.38+d.39+d.40+d.41+d.42+d.43+d.44+d.45+d.46+d.47+d.48+d.49+d.50+d.51+d.52+d.53+d.54+d.55+d.56+d.57+d.58+d.59+d.60, data= d2.i, family = "binomial", 
              Ntrials = 1, #Ntrials = 1 for bernoulli
              control.family = list(control.link=list(model="logit")),
              control.fixed = list(
        mean=  0 ,
        prec= 1.5),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, waic= TRUE))
summary(m2.1.i)



```

## 2.2 varying intercepts model


### 2.2 rethinking

```{r 8.2.2 re}
m2.2 <- ulam( alist(
C ~ bernoulli( p ),
logit(p) <- a[did],
a[did] ~ normal( a_bar , sigma ),
a_bar ~ normal( 0 , 1.5 ),
sigma ~ exponential( 1 )
) ,data=dat_list , chains=4 , cores=4 , log_lik=TRUE )

precis(m2.2, depth= 2)

```

### 2.2 inla

```{r 8.2.2 inla}

m2.2.i <- inla(use.contraception ~ f(district_id, model="iid"), data= d2.i, family = "binomial", 
              Ntrials = 1, #Ntrials = 1 for bernoulli
              control.family = list(control.link=list(model="logit")),
              control.fixed = list(
        mean.intercept=  0 ,
        prec.intercept= 1.5),
              control.predictor=list(link=1, compute=T),
              control.compute=list(config=T, waic= TRUE))
summary(m2.2.i)
bri.hyperpar.summary(m2.2.i)

```

Side note: this is how you calculate the sd from the hyperprior ($\sigma$)

```{r 8.2.2 inla hyper sd}
bri.hyperpar.summary(m2.2.i)

# hyperparameter of the precision
m2.2.i.prec <- m2.2.i$internal.marginals.hyperpar

#transform precision to sd using inla.tmarginal
#m2.2.i.prec[[1]] is used to access the actual values inside the list
m2.2.i.sd <- inla.tmarginal(function(x) sqrt(exp(-x)), m2.2.i.prec[[1]])
#plot the post of the sd per district (sigma)
plot(m2.2.i.sd)
#summary stats for the sd 
m2.2.i.sd.sum <- inla.zmarginal(m2.2.i.sd)
# this coincides perfectly with the result from bri.hyperpar.summary
```


## 2.3 plot of posterior mean probabilities in each district

Now let’s extract the samples, compute posterior mean probabilities in each district, and plot it all:

### plot rethinking 

```{r 8.2.3 plot rethinking }

post1 <- extract.samples( m2.1 ) 
post2 <- extract.samples( m2.2 )
p1 <- apply( inv_logit(post1$a) , 2 , mean ) 
p2 <- apply( inv_logit(post2$a) , 2 , mean )
nd <- max(dat_list$did)
plot( NULL , xlim=c(1,nd) , ylim=c(0,1) , ylab="prob use contraception" , xlab="district" )
points( 1:nd , p1 , pch=16 , col=rangi2 ) 
points( 1:nd , p2 )
abline( h=mean(inv_logit(post2$a_bar)) , lty=2 )
 
```

### plot inla

https://people.bath.ac.uk/jjf23/inla/oneway.html

https://people.bath.ac.uk/jjf23/brinla/reeds.html


**posterior mean for each district a for the idex fixed effect model m2.1:** 

```{r summary table inla fix, results = FALSE}

# m2.2.i$summary.fixed[[1]] would gives us the summary we want but not in the response scale, we need to  transform it using the inverse logit 

inverse_logit <- function (x){
    p <- 1/(1 + exp(-x))
    p <- ifelse(x == Inf, 1, p)
    p }

#inla.tmarginal : apply inverse logit to all district marginals 
#inla.zmarginal : summary of the logit-transformed marginals 
# we eliminate the first element of this list, the intercept.
m2.1.i.fix<- lapply(m2.1.i$marginals.fixed, function (x) inla.zmarginal( inla.tmarginal (inverse_logit, x )))[-1]

```

**posterior mean for each district a for the varying intercept model m2.2:** 

```{r summary table inla ran, results = FALSE}

# m2.2.i$summary.random[[1]] would gives us the summary we want but not in the response scale, we need to  transform it using the inverse logit 

#inla.tmarginal : apply inverse logit to all district marginals 
#inla.zmarginal : summary of the logit-transformed marginals 
m2.2.i.rand<- lapply(m2.2.i$marginals.random$district_id, function (x) inla.zmarginal( inla.tmarginal (inverse_logit, x )))
```


```{r 8.2.3 plot inla }

# sapply(m2.2.i.rand, function(x) x[1]) extracts the first element (the mean) from the summary of the posterior of each district
m2.i.mean <- bind_cols(district= 1:60,mean.m2.1= unlist(sapply(m2.1.i.fix, function(x) x[1])), mean.m2.2=unlist(sapply(m2.2.i.rand, function(x) x[1])))

m2.2.i.abar <- inla.zmarginal( inla.tmarginal (inverse_logit, m2.2.i$marginals.fixed[["(Intercept)"]] ))

m2.i.district.plot <- ggplot() +
  geom_point(data= m2.i.mean, aes(x= district, y= mean.m2.1), color= "blue", alpha= 0.5)+
  geom_point(data= m2.i.mean, aes(x= district, y= mean.m2.2), color= "black", alpha= 0.5, shape= 1)+
  geom_hline(yintercept=m2.2.i.abar[[1]], linetype='longdash') +
  ylim(0,1)+
  labs(y = "prob use contraception")+
  theme_bw()
  

m2.i.district.plot


```

The blue points are the fixed estimations. The open points are the varying effects. As you’d expect, they are shrunk towards the mean (the dashed line). Some are shrunk more than others. The third district from the left shrunk a lot. Let’s look at the sample size in each district:

```{r 8.2.3 table}
 table(d$district_id)
```

District 3 has only 2 women sampled. So it shrinks a lot. There are couple of other districts, like 49 and 54, that also have very few women sampled. But their fixed estimates aren’t as extreme, so they don’t shrink as much as district 3 does.
All of this is explained by partial pooling, of course.


# 3. 


I don't really care about ordered categorical data so i'm going to skip exercise 3.



